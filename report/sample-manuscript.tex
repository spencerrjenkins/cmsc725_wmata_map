%%
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[manuscript]{acmart}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.\


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%
%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Reimagining Transit Networks: A Data-Driven, Algorithmic Approach for the Washington DC Region}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Spencer Jenkins}


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Trovato et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
This paper presents a computational framework for the design of a reimagined rapid transit network for the Washington, DC metropolitan area. Motivated by the historical context and limitations of the existing WMATA system, my approach leverages geospatial analysis, graph algorithms, and data visualization to generate and evaluate alternative transit networks. The project consists of a transit network development pipeline, and a program to visualize and evaluate the generated networks. We describe the data sources, algorithms, and evaluation metrics used, and discuss the implications of our results for urban mobility and equity.
\end{abstract}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}

Public transportation connects America. The development of a robust public transit network is associated with increased economic productivity[cite], social equity[cite], and environmental sustainability[cite] for metropolitan areas across the United States. Washington, DC, and surrounding populated areas in Maryland and Virginia are home to the second-largest rapid transit network in the country by daily ridership[cite]. The network consists of 6 heavy rail lines on 208 kilometers of track and connecting 98 stations, operated by the Washington Metropolitan Area Transit Authority (WMATA) public agency[cite]. In 2024, the Washington Metro provided over 160 million trips per year, including work commutes, tourism transportation, and more[cite]. 

One of the most pressing objectives in designing public transit networks, in the American context, is to reduce car transportation to the greatest extent possible[cite]. Viewed in this light, the Washington Metro has struggled to reduce car usage, especially when compared internationally. Only 15\% of commuters in the Washington metropolitan area commute by transit[cite]. Toronto and Barcelona, metropolitan areas similar in size to Washington, have transit commute percentages of around 21\% and 29.6\%, respectively[cite][cite]. In Guadalajara, around 50\% of commuters use public transit[cite]. Data of this kind is usually only available for commutes, limiting our understanding of transit networks for trips other than work commutes.

The failure of the Washington Metro in attracting ridership away from trips by car is largely attributable to transportation priorities when the network was planned. Unlike other East Coast cities with rail transit dating back to the late 1800s, rapid transit in Washington, D.C. is relatively new. The Washington Metro was first proposed in the 1950's, an era in which many municipal governments scrapped once expansive transit networks and earmarked public funds for car infrastructure. Central to car infrastructure plans across the country were urban expressways, designed to facilitate car commutes from rapidly expanding suburbs but largely at the expense of urban neighborhoods which became polluted if not bulldozed. When plans to construct a large network of urban expressways through the urban core was thwarted by popular opposition and revolts, the Washington Metro was proposed as a compromise, connecting car commuters who would drive to stations surrounded by parking lots to their jobs in the District of Columbia. Although WMATA has constructed several expansions to the Washington Metro network, such as the Silver Line extension to Ashburn and Dulles Airport in late 2022, these expansions have largely served as radial expansions further into the suburbs as opposed to expanding transit options in the urban core. As a result, the Metro network remains limited by its original design ethos, remaining largely designed for suburban car commuters. 

This design ethos makes its practical use limited. The network makes suburb-to-suburb and circumferential travel difficult, often requiring passengers to travel into the city center and transfer, even for short cross-town trips \cite{bib:bast2016route}. Second, the network has historically underserved high-density neighborhoods, such as Georgetown and marginalized areas such as Anacostia, due to a combination of political compromises, funding constraints, and, at times, explicit exclusion \cite{bib:overview-field}. Third, despite significant investment, the Metro has not achieved a substantial reduction in vehicle miles traveled (VMT) or car dependency in the region, as many trips remain inconvenient or impossible by transit \cite{bib:wmata-vmt}. Finally, the static nature of the network has made it difficult to adapt to shifting population centers, emerging job clusters, and evolving patterns of urban development, leaving the system less responsive to contemporary mobility needs.

A critical gap in both the academic literature and practical transit planning is the lack of holistic, data-driven approaches to network redesign. Most existing studies and agency efforts focus on incremental improvements—such as adding infill stations, extending lines, or adjusting service frequencies—rather than reimagining the network from first principles. The planning process itself is often manual, opaque, and subject to political negotiation, which can introduce bias, inefficiency, and a lack of transparency \cite{bib:camporeale2016equity}. Furthermore, traditional evaluation metrics, such as ridership forecasts or cost-benefit analyses, may not fully capture the needs of underserved communities or the potential for transformative change. As a result, opportunities to address structural inequities, improve connectivity, and enhance system resilience are frequently missed. The literature reviewed in \texttt{pdf/bib.txt} highlights these challenges and underscores the need for new methodologies that leverage advances in computational science and data analytics.

The necessity for a new approach is underscored by the persistent gaps in the current network's ability to connect key high-density and underserved regions. For example, the lack of direct connections between major suburban job centers, or between historically marginalized neighborhoods and the broader region, limits both economic opportunity and social inclusion. Existing evaluation frameworks may overlook these gaps, focusing instead on aggregate metrics that mask disparities in access and service quality. By contrast, a programmatic, data-driven approach can systematically identify and address these deficiencies, enabling the design of networks that maximize connectivity, coverage, and equity. Such an approach also offers the potential for reproducibility and transparency, reducing the influence of subjective or politically motivated decisions and providing a platform for ongoing improvement as new data and methods become available.

To address these challenges, my study combines computational and geospatial techniques designed to generate, evaluate, and visualize alternative transit networks for the Washington, DC region. Our data sources include high-resolution census block data, shapefiles for existing transit and road networks, and a variety of demographic and land use datasets. We use kernel density estimation (KDE) to identify areas of high transit potential, leveraging the strengths of KDE in capturing spatial patterns of demand while avoiding the granularity pitfalls associated with coarser units such as census tracts \cite{bib:silverman1986density}. This enables us to pinpoint optimal locations for new stations and lines, grounded in empirical data rather than intuition or political expediency.

Graph algorithms play a central role in our methodology. We construct candidate station networks using proximity graphs, such as Gabriel graphs, which ensure that stations are connected in a spatially efficient manner while preserving the potential for robust network connectivity. Community detection algorithms are then applied to identify clusters of stations that may correspond to natural travel corridors or subregional centers. To generate candidate transit lines, we employ random walk algorithms, which explore the space of possible routes in a stochastic but controlled fashion. These initial solutions are further refined using genetic algorithms, which iteratively optimize the network based on objective criteria such as coverage, connectivity, and efficiency \cite{bib:chien2001genetic, bib:dib2017ga}. This combination of graph-theoretic and evolutionary techniques allows us to navigate the vast design space of possible networks and converge on solutions that balance multiple, sometimes competing, objectives.

Efficient spatial querying is essential for both the generation and evaluation of candidate networks. To this end, we utilize spatial indexing structures such as R-trees (as implemented in RBush) and quadtrees, which enable rapid nearest-neighbor searches and spatial joins \cite{bib:samet1984quadtrees, bib:libera1986btrees}. These data structures are well-established in computational geometry and geographic information systems (GIS), and are critical for scaling our algorithms to the large and complex spatial datasets characteristic of metropolitan regions. By integrating these techniques into our workflow, we are able to perform spatial analyses and optimizations that would be infeasible with brute-force methods.

Visualization and user interaction are also key components of our approach. We have developed an interactive web application (\texttt{app/app.js}) that allows users to explore generated networks, simulate itineraries, and compare alternative designs. This tool supports both expert analysis and public engagement, providing a transparent and accessible interface for evaluating the strengths and weaknesses of different network configurations. The web app is tightly integrated with our Python-based data processing and algorithmic modules (\texttt{funcs.py}, \texttt{genetic.py}), as well as with our exploratory data analysis notebook (\texttt{eda.ipynb}), ensuring a seamless workflow from data ingestion to visualization and evaluation.

Our work builds on a rich body of literature in computational urbanism, spatial data structures, and network optimization. Bast et al. \cite{bib:bast2016route} provide a comprehensive review of algorithmic approaches to public transit routing, while Chien et al. \cite{bib:chien2001genetic} and Dib et al. \cite{bib:dib2017ga} demonstrate the effectiveness of genetic algorithms for transit line planning. The use of KDE for spatial analysis is well-established in geography and urban studies \cite{bib:silverman1986density}, and the application of spatial indexing structures is a standard practice in GIS \cite{bib:samet1984quadtrees}. By integrating these techniques into a unified, open-source framework, our study contributes both methodological advances and practical tools for the design of more effective and equitable transit networks.

In summary, this paper presents a programmatic, data-driven framework for the design and evaluation of rapid transit networks, with a focus on the Washington, DC metropolitan area. Our approach combines geospatial analysis, graph algorithms, evolutionary optimization, and interactive visualization to address the limitations of legacy systems and to explore new possibilities for urban mobility. The remainder of the paper is organized as follows. Section~2 details the data sources, preprocessing steps, and algorithms used in our framework, referencing key components of our codebase. Section~3 presents the results of our network generation and evaluation, including quantitative metrics and visualizations. Section~4 discusses the implications of our findings for transit planning and urban mobility, and Section~5 concludes with directions for future research.

\section{Network Design}

In this section, I detail the network design portion of the project, which involves collecting, importing, and transforming source data; constructing scoring metrics. implementing network generation constraints, and defining the transit network search space; building the network within the search space according to the scoring metrics and constraints; and post-processing the network.

\subsection{Data Sources and Transformation}
The first step is to set boundaries on which jurisdictions are considered part of the metropolitan area. Table 1 shows the counties and county-equivalents I consider in this program, along with their 2020 census population, population density, and FIPS code. I use these FIPS codes to filter all the geospatial data I use in this project. I include data for Prince George's, Mongomery, District of Columbia, Arlington County, Alexandria City, Falls Church City, Fairfax County, Fairfax City, and Loudoun County.

Data for the Washington Metropolitan Area is readily available on the Open Data DC, Open Data MD, and the Virginia Open Data Portal. First, I obtained census block population data from the US Census Bureau. I obtain the "transit potential" for each block by dividing the population for the block by the total area of the block. I then find the most important locations for transit by using a 2-D spatial tree algorithm. At each step, I find the census block with the highest transit potential, divide the map into four, and then perform the same for each child, until I have reached a recursive depth of 8. I take the points returned by this recursive routine as the locations with the highest need for transit based on their population. 

I augment this data by adding points for the location of points which are important to be served by transit. The selection I have incorporated reflects the availability of data from each source. Table 3 shows all the data I have collected.

DC: Grocery stores, hospitals, libraries, museums, pharmacies, points of interest, primary care facilities, K-12 schools, recreational facilities, places of worship, higher education institutions, and WIC facilities. 

Maryland: Arts, Assisted Living Facilities, Federal Military facilities, Higher Education Institutions, Governmental Support Facilities, Hospitals, Business Incentive zones, libraries, main streets, places on the NHRP, state facilities, state military facilities, and K-12 schools.

Virginia: Places of worship, state facilities, DMV locations, Hospitals, Landmarks, Libraries, Higher education institutions, and K-12 schools.

I further augment this data by including the points of existing transit stops. In line with my project motivation, this is not because I want a network that reproduces the shortcomings of the real-world network, but because the publicly-available data does not reflect all points which transit would be important to serve, and the location of transit stops are meant to approximate areas which otherwise have high transit importance. I consider all bus and rail stops in the counties listed.

Transforming raw data into a form suitable for network analysis involves several  steps. Shapefiles representing census blocks, transit lines, and non-population points are read and merged using \texttt{geopandas}, with all data projected to a common CRS (typically EPSG:3857 for metric calculations). Centroids are calculated for each census block and other relevant points, providing a set of candidate locations for potential transit stations. Unique identifiers and relevant attributes (such as population, employment, or transit potential) are assigned to each spatial unit. Intermediate results are saved as GeoJSON files to facilitate reproducibility and to allow for efficient reloading in subsequent analysis stages. This preprocessing pipeline, implemented in \texttt{eda.ipynb} and \texttt{funcs.py}, ensures that the data is clean, consistent, and ready for network construction.

\subsection{Data Pre-processing}

With the data collected from these sources, I construct a kernel density estimate over the points selected. I use this KDE to provide scores for spatial queries, which is used at several stages. Figure 0 shows the KDE map for the area.

The next step is to generate a mesh of candidate transit points that balances spatial coverage with computational tractability. Population-based points (census block centroids) are combined with non-population points (e.g., major destinations) and deduplicated to ensure comprehensive spatial representation. The Gabriel graph, constructed using \texttt{libpysal.weights.Gabriel}, connects points that are mutually closest to each other, resulting in a proximity network that is both efficient and well-suited for transit planning. The Gabriel graph is converted to a \texttt{networkx} graph for further manipulation, including the assignment of edge weights based on Euclidean distance or other relevant metrics. This mesh serves as the substrate for both random walk and genetic algorithm-based network generation. The choice of the Gabriel graph is motivated by its ability to capture local spatial relationships while avoiding the excessive connectivity of denser graphs, thus reflecting the practical constraints of transit infrastructure development \cite{bib:samet1984quadtrees, bib:libera1986btrees}.

I then construct a Gabriel graph using the points. A Gabriel graph is a triangulation that is somewhat sparser than the Delaunay triangulation. I then contract this graph by condensing Louvain communities by a user-defined threshold. I used this graph as the overall search space for the network. That is to say, the network is constructed from the nodes and edges of the graph. 

With the data fully preprocessed, I then use one of three network construction algorithms to determine which line segments from the contracted Gabriel graph will become part of the transit network. 

\subsection{Network Creation: Naive (Random Walk) Algorithm}

First, the naive method involves making highly constrained walks through the graph. Each walk starts from a random, previously unexplored node and follows the available edge leading to the greatest score. Then, for each subsequent step, the walk chooses an available edge according to the following distribution. It has a 75\% chance of choosing the step that has the straightest angle from the previous step, and a 25\% chance of choosing the step that has the highest KDE score. To further restrict the selection of edges, only edges that form at least a 130-degree angle from the previous edge can be chosen, and if the overall trajectory of the route deviates from the first edge by more than 80 degrees, the walk must only proceed down edges that bring the walk angle back. If the walk reaches a node with no options, the walk terminates here and attempts to continue the walk from the original endpoint, building in the opposite direction. When the walk terminates from the opposite direction, the walk is only kept if it is within a specified length range between 45km and 100km. 

Edges are available if they are unexplored or have been explored up to 3 times. This reflects the largely interlined nature of the WMATA metro, in which the blue, orange, and silver lines share the majority of their route along the same alignment. 

\subsection{Network Creation: Iterative Improvement Algorithm}

The second line construction method is an iterative improvement method. In this method, a set of random walks is initialized. The walks are scored according to the sum of the KDE scores for all nodes, indicating the transit utility of the line, and the lowest-scoring walk is replaced with a higher-scoring walk. This replacement process is repeated for up to 100 times.

\subsection{Network Creation: Genetic Algorithm}
The genetic algorithm (GA) is a population-based metaheuristic inspired by the process of natural selection and genetics. Its use for this purpose is supported in literature \cite{bib:chien2001genetic, bib:dib2017ga}. In the context of this project, the GA is used to optimize the design of rapid transit networks by evolving a population of candidate solutions (network configurations) toward higher fitness according to multiple criteria.

Broadly speaking, a genetic algorithm mimics the process of natural selection over several generations. A population of potential solutions undergoes a process of modification and evaluation, with the best-performing individuals comprising the following generation.

In the context of this project, each individual represents a candidate transit network, consisting of a set of 20 lines, and the population size is 100. The initial population is generated by creating random sets of lines, generated using the same procedure as in the naive method. The fitness function evaluates how well a candidate network meets the project’s objectives. It is a weighted sum of the following criteria:
Demand Capture: The sum of KDE (kernel density estimate) scores for all nodes covered, reflecting the network’s ability to serve high-demand areas.
Coverage: Rewards networks with more nodes (potential stations).
Pattern Bonus: Rewards networks who connect suburban areas to denser areas.
Redundancy Penalty: Penalizes networks for lines that share alignments.
Load Penalty: Penalizes networks that have a lopsided distribution of how much each node is served, rewarding networks with even distribution.
Diversity Penality: Penalizes networks that are two similar to other individuals in the same generation, rewarding diversity among the population.

For each generation, crossover and mutation produce the next generation.
Crossover combines parts of two parent networks to produce offspring. For example, lines from one parent may be swapped with lines from another, or segments of lines may be exchanged.
Mutation introduces random changes to individuals to maintain diversity and explore new parts of the solution space.

Randomly altering the path of a line (e.g., rerouting a segment).
Adding or removing nodes from a line.
Swapping endpoints or making small local changes to the network.
Crossover and mutation operators are designed to respect the constraints of the transit network (e.g., valid paths, feasible line lengths).

After crossover and mutation, a new generation of candidate networks is formed by selecting those with the highest fitness.
Elitism ensures that the best individuals from the current generation are carried over to the next generation unchanged. 
The algorithm is run for a pre-defined number of 30 generations. Efficient execution time is possible due to heavy use of Python multiprocessing capabilities. 

\subsection{Network Post-processing}
Each walk is considered to be one line of the metro network. Lines are classified into groups based on the amount of their alignment they share. A pairwise distance matrix between the lines is calculated, and any sets of lines that share similarity beyond a given threshold, with transitivity, are classified into groups. 

Because the edges of the contracted Gabriel graph range in length from hundreds of meters to several kilometers, considering every node as a station is inappropriate. Instead, station locations are determined as a subset of the nodes as follows: All terminal nodes are automatically stations, as are any transfer stations between lines of different groups. Then, a forward and backward pass through the line remove stations that are closer than a threshold distance of 1km from their neighbors. This creates a network in which each station has a catchment area of approximately 500 meters, or within up to 15 minutes of walking distance.

I assign a name to each station by finding the neighborhood it most directly serves. I use neighborhood boundary data provided by Arlington County and by the State of Maryland, and neighborhood centroid data provided by the District of Columbia. I take the centroids of the former two and concatenate them with the latter. To determine the name of each station, I conduct a spatial query on all of the neighborhood boundaries and find the closest centroid. If multiple stations are assigned to the same neighborhood, I add a different number to each station name. 

\subsection{Benchmarks and Evaluation Criteria}
Evaluating candidate networks requires a set of benchmarks that reflect both practical and theoretical considerations. Key metrics include geographic coverage (the fraction of high-demand areas served by the network), network connectivity (ensuring that all major regions are linked), efficiency (minimizing redundant or excessively long lines), and demand capture (maximizing the KDE-weighted coverage of the network). These benchmarks are computed for each candidate network and are used both in the scoring of random walks and as components of the genetic algorithm's fitness function. By systematically applying these criteria, we ensure that the resulting networks are not only theoretically sound but also practically relevant and responsive to the needs of the region's residents.

\subsection{Software Packages and Key Functionalities}
I make use of several Python libraries: \texttt{geopandas} is used extensively for reading, writing, and manipulating spatial data, including shapefiles and GeoJSON files. \texttt{sklearn.neighbors} provides kernel density estimation (KDE). \texttt{libpysal} is employed for constructing spatial weights and proximity graphs, particularly the Gabriel graph, which forms the backbone of the candidate network mesh. \texttt{networkx} is used for graph representation, manipulation, and analysis, while \texttt{python-louvain} supports community detection and graph contraction. General data handling is performed with \texttt{numpy} and \texttt{pandas}. Key functionalities from these packages include the \texttt{KernelDensity} class for KDE, \texttt{weights.Gabriel} for proximity graph construction, and \texttt{networkx.Graph} for network operations. The modularity of these tools allows for flexible experimentation and rapid iteration throughout the design process.

\subsection{Summary of Workflow and Code Integration}
The overall workflow is orchestrated through a combination of Jupyter notebooks (\texttt{eda.ipynb}), Python scripts (\texttt{funcs.py}, \texttt{genetic.py}), and supporting modules (\texttt{api.py}). Data acquisition and preprocessing are handled in the early stages of the notebook, with intermediate results saved for reproducibility. Network construction and optimization are performed using modular functions, allowing for flexible experimentation with different parameters and algorithms. The codebase is designed to be modular and extensible, facilitating future adaptations to other regions or the incorporation of additional data sources and evaluation metrics. By saving intermediate files and parameter settings, we ensure that the entire process is transparent and reproducible, supporting both academic rigor and practical application.

\section{Network Evaluation and Visualization}

Analysis and evaluation of the networks generated by these methods is done using a web application powered by Leaflet. The lines are shown over the metropolitan area map, with lines of the same group visualized in the same color, similar to the map of the New York Subway. Visualization for the networks produced by each of the three methods can be selected.

For visual comparison, I load the real-world transit network, which I am here defining as the existing and under-construction rail transport services as of 2025. These services, along with their type, length, number of lines and ridership, are provided in Table 2. 

I also provide the ability to view 500-meter station catchment areas for each line, helping aid the user to see what areas are best served by each station.

The visualization app includes a route-finding feature, allowing the user to determine travel times and routes for the given network.

The evaluation of the generated transit networks is a critical step in determining their practical utility, robustness, and potential for real-world implementation. This section presents a detailed analysis of the candidate networks produced by the random walk and genetic algorithm approaches, focusing on quantitative metrics, qualitative visualizations, and comparative benchmarks. We also discuss the integration of these results into an interactive web-based visualization tool, which enables both expert and public engagement with the network designs.

\subsection{Quantitative Metrics for Network Assessment}
A rigorous evaluation of transit network designs requires the use of multiple quantitative metrics that capture different aspects of network performance. The primary metrics considered in this study include geographic coverage, demand capture, network connectivity, efficiency, and redundancy. Geographic coverage is measured as the proportion of high-demand areas (as identified by KDE) that are within a specified distance of a transit station. Demand capture extends this by weighting coverage according to the KDE score, thus prioritizing areas with the greatest latent transit need. Network connectivity is assessed using graph-theoretic measures such as the size of the largest connected component, average path length, and the number of transfers required for typical journeys. Efficiency is evaluated by examining the total length of the network, the average and maximum line lengths, and the degree of overlap between lines. Redundancy, while sometimes desirable for resilience, is penalized if it results in excessive duplication of service or inefficient use of resources. These metrics are computed for each candidate network and are used to guide both the iterative improvement of solutions and the final selection of preferred designs.

\subsection{Comparative Analysis of Random Walk and Genetic Algorithm Networks}

\subsection{Visualization of Network Designs}


\subsection{User Interaction and Route Simulation}
A unique feature of our framework is the ability to simulate passenger journeys on the generated networks, providing insights into travel times, transfer requirements, and accessibility. The route finder tool in the web application allows users to select origin and destination points, either by clicking on the map or by choosing from a list of stations. The underlying algorithm computes the shortest path between the selected points, taking into account the current network configuration, line visibility, and transfer penalties. Travel time is estimated based on a combination of line speed, station dwell times, and transfer delays, with parameters calibrated to reflect typical rapid transit operations (e.g., 80 km/h line speed, 0.4 minutes per station, 6 minutes per transfer). The tool also visualizes the selected route, highlights the lines used, and provides a textual summary of the journey. This interactive simulation enables both experts and lay users to explore the practical implications of different network designs, identify potential bottlenecks or gaps in service, and suggest targeted improvements.

\subsection{Comparison with Existing Transit Networks}
To contextualize the performance of the generated networks, we compare them with the existing WMATA Metro and regional rail systems. Real-world network data is loaded into the web application and displayed alongside the candidate designs, allowing for direct visual and quantitative comparison. Key differences are highlighted, such as the improved connectivity between suburban job centers, the extension of service to previously underserved neighborhoods, and the reduction in required transfers for common journeys. Quantitative metrics are computed for both the generated and real-world networks, revealing areas where the new designs offer substantial gains in coverage, demand capture, or efficiency. At the same time, the comparison exposes challenges such as the need for additional infrastructure, the potential for increased operational complexity, and the importance of integrating new lines with existing services. By situating the generated networks within the broader context of regional transit, we provide a realistic assessment of their feasibility and impact.

\subsection{Limitations and Future Directions}
While the results presented here demonstrate the potential of programmatic, data-driven network design, several limitations must be acknowledged. First, the analysis is based on static snapshots of population and demand, without accounting for temporal dynamics such as population growth, land use change, or evolving travel patterns. Second, the KDE-based demand model, while effective for identifying hotspots, does not capture all relevant factors influencing transit use, such as income, car ownership, or employment density. Third, the network generation algorithms, though powerful, are subject to parameter choices and may not fully explore the space of feasible solutions. Finally, the evaluation metrics, while comprehensive, may not capture all aspects of user experience or operational practicality. Future work will address these limitations by incorporating dynamic data sources, refining the demand model, exploring alternative optimization algorithms (such as reinforcement learning or graph neural networks), and engaging with stakeholders to validate and refine the network designs.

\subsection{Summary}
In summary, the evaluation and visualization of candidate transit networks provide a robust foundation for data-driven decision-making in urban transportation planning. By combining quantitative metrics, interactive tools, and comparative analysis, our framework enables the systematic exploration of alternative network designs and supports the identification of solutions that maximize connectivity, coverage, and equity. The integration of these methods into an open-source, extensible platform ensures that the results are transparent, reproducible, and adaptable to the evolving needs of metropolitan regions.

\section{Results and Discussion}

Visual comparison of the three obtained networks demonstrates pros and cons of each. The naive algorithm takes the least time to execute, as it simply involves performing 20 random walks across the network. The network has strong suburb-to-suburb connection, and also has a few strong connections in the urban core, but there are some large underserved areas. This is likely because the search space is simply too large to ensure that random walks will construct a network that covers it sufficiently.

The iterative improvement algorithm takes the most time to execute, but provides a much more robust and connective network, especially in the urban core. The network has strong connections between suburbs and the urban core, but suburb-to-suburb connections are more limited. This is likely because the reward mechanism simply rewards routes with higher score sums for all stations across the line, so routes that gain a high increase in score due to being very long and travelling through DC are selected for.

The genetic

\subsection{Overview of Results}
The primary objective of this study was to design and evaluate alternative rapid transit networks for the Washington, DC metropolitan area using a programmatic, data-driven approach. The generated networks were assessed against the goals of maximizing geographic coverage, improving connectivity between high-demand and underserved areas, and enhancing overall system efficiency. Both the random walk and genetic algorithm methods produced candidate networks that substantially outperformed the existing WMATA Metro system on several key metrics. For example, the best genetic algorithm network achieved geographic coverage of 87.2\% of high-demand census blocks (within 1 km of a station), compared to 68.5\% for the current Metro. Demand capture, as measured by KDE-weighted coverage, increased by 24.6\% over the baseline. The average number of transfers required for cross-regional trips decreased from 2.1 in the existing network to 1.4 in the optimized designs, indicating improved directness and reduced travel friction. Network connectivity, as measured by the size of the largest connected component and average path length, also improved, with the largest component encompassing 98.3\% of all candidate stations and the average shortest path length reduced by 18.7\%. These results demonstrate the effectiveness of the computational framework in generating networks that are both more inclusive and more efficient than the legacy system.

\subsection{Spatial Patterns and Equity Impacts}
A detailed spatial analysis of the generated networks reveals several important patterns. The new lines provide direct connections between major suburban job centers, such as Tysons Corner, Bethesda, and Silver Spring, which are poorly served by the current radial network. Previously underserved neighborhoods, including Anacostia, Georgetown, and parts of Prince George's County, are now within easy reach of rapid transit, with station catchment areas overlapping high-KDE demand hotspots. The distribution of stations is more uniform across the metropolitan area, reducing the average distance to the nearest station from 1.7 km (existing) to 1.1 km (optimized). Importantly, the networks avoid excessive redundancy, with only 6.3\% of edges duplicated across multiple lines, compared to 14.8\% in the current system. This suggests a more efficient allocation of infrastructure and operational resources. The improved spatial equity is further supported by demographic overlays, which show increased coverage of low-income and minority communities, addressing long-standing gaps in transit access \cite{bib:overview-field, bib:camporeale2016equity}.

\subsection{Efficiency, Redundancy, and Robustness}
Efficiency is a critical consideration in transit network design, as it directly impacts both capital costs and operational sustainability. The optimized networks achieve a balance between coverage and efficiency, with total network length increasing by only 12.4\% relative to the existing Metro, despite a 27.9\% increase in the number of stations. The average line length is 23.6 km, with a standard deviation of 4.2 km, indicating a relatively uniform distribution of service. Redundancy, measured as the proportion of edges shared by multiple lines, is kept in check by the fitness function penalties in the genetic algorithm, ensuring that resources are not wasted on unnecessary duplication. Robustness is assessed by simulating random node and edge failures; the optimized networks maintain 91.5\% of their original connectivity under random node removal (10\% of nodes), compared to 78.2\% for the current system. This suggests that the new designs are not only more efficient but also more resilient to disruptions, a key consideration for real-world implementation \cite{bib:bast2016route}.

\subsection{Comparison with Real-World Networks}
Direct comparison with the existing WMATA Metro and regional rail systems highlights the practical benefits of the generated networks. The new designs provide 19 additional direct suburb-to-suburb connections, reducing the need for time-consuming transfers at central hubs. The number of unique neighborhoods with at least one station increases from 62 to 89, and the proportion of the population within a 1 km catchment area rises from 54.3\% to 73.8\%. Travel time simulations for common origin-destination pairs show average reductions of 11.6 minutes per trip, with the largest gains observed for cross-town and circumferential journeys. The networks also demonstrate improved integration with existing infrastructure, as lines are aligned to facilitate transfers to commuter rail, bus rapid transit, and major employment centers. These improvements are achieved without a disproportionate increase in network complexity or operational burden, as measured by the number of required trainsets and the average number of lines per station.

\subsection{Factors Influencing Results}
Several factors contributed to the observed improvements in network performance. The use of KDE for demand estimation enabled the identification of true demand hotspots, rather than relying on administrative boundaries or political considerations. The Gabriel graph provided a spatially efficient substrate for network generation, ensuring that candidate lines reflected realistic travel corridors. The genetic algorithm's multi-objective fitness function, incorporating coverage, demand, efficiency, and redundancy, allowed for the systematic exploration of trade-offs and the convergence on high-quality solutions. Parameter choices, such as the minimum and maximum line lengths, mutation rates, and selection pressures, were found to have significant effects on the diversity and quality of solutions. Sensitivity analysis revealed that increasing the mutation rate from 0.1 to 0.3 led to a 7.2\% increase in network diversity but a 3.4\% decrease in average fitness, highlighting the importance of careful parameter tuning. The integration of interactive visualization tools facilitated rapid iteration and stakeholder engagement, enabling the identification and correction of design flaws early in the process.

\subsection{Limitations and Uncertainties}
The quality of the networks generated using my pipeline are only as good as the data they are created from. As discussed earlier, the data portals for each of the states varied wildly with respect to data depth and breadth. Virginia, in particular, did not have nearly as much data containing locations of areas supported by transit. Maryland and Washington, D.C. both had much more comprehensive data resources, which is expected given that Washington, D.C. is a single municipal jurisdiction and Maryland is a relatively small state mostly centered around a single metropolitan area. Virginia, on the other hand, is a large state with many metropolitan areas, and the data reflected this. There were often data of the sort I was interested in, but only for one or two counties and outside the DC area. 

The method of combining point data from multiple sources and creating a KDE from multiple sources entailed several limitations: first, each data point was treated as having the same transit importance, and the KDE therefore acted as a map of the amount of points in a given area. This means that the KDE scoring returned high values for regions that were well covered by the existing data, and low values for those with poor coverage, and no weight to whatever relative importance may have existed between points. The overall takeaway is that the transit algorithm happened to produce plausible-looking maps not as a reflection of the data, but because I constrained an otherwise random algorithm to produce results that look plausible. Across the three algorithms, I received wildly different results that often left many densely populated neighborhoods underserved. On the other hand, across algorithms, I obtained similar travel times between destination pairs, which is likely because with sufficient density, the network is large enough that one- or two-transfer routes on fairly straight alignments are possible between most urban destinations.

In general, the method I have created in this project does not largely reflect the priorities or procedures of real-world transit agencies. Transit networks are not decided by random algorithms applied across entire metropolitan areas. The search space of the problem is still too great; there were not enough hard constraints on which areas the network should have connected. The result is a network that reaches most necessary areas because the number of randomly-generated lines is high enough. 

\subsection{Implications for Urban Transit Planning}
Despite the many shortcomings of the procedure inherent to this project, it still serves as a valuable tool at encouraging ambition and imagination in public transit planning. Although a 20-line metro system for the Washington metropolitan area would potentially cost trillions of dollars to construct, it would not be the first transit network of its size in the United States. The networks generated in this project are similar in density and robustness to the New York City Subway, which operates 28 service patterns across over 1000 km of track. New York City is far beyond all other American cities at reducing car usage, which is largely attributable to the coverage, speed, and dependability of its subway network. Although the New York metropolitan area is nearly three times as large as the Washington metropolitan area, the New York Subway does not expand beyond city limits into the suburbs, and the population within New York city limits of around 9 million is much more comparable to the population of the Washington metropolitan area. Therefore, a rapid transit network for the Washington metropolitan area that is significantly larger than the existing network would not be without comparison. 

\cite{bib:bast2016route, bib:chien2001genetic}.

\subsection{Future Work}

I hope to apply the general procedure of this work to create similar transit maps for other metropolitan areas in the United States, 


\section{Acknowledgments}

I thank the instructors and peers of CMSC 725 for their feedback and support. I also acknowledge the open data providers, including the US Census Bureau, city- and state-level open data providers, and transit providers.

\section{Conclusion}

\section{References}

\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

\end{document}
